{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 1: Prompt engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we will be exploring google's python wrapper around their ai API\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "\n",
    "#generate your own key on https://aistudio.google.com/apikey\n",
    "gemini_api_key = 'AIzaSyDMzirF3-0z94a8On2kjVGr4SzKYlVkFo4'\n",
    "\n",
    "genai.configure(api_key=gemini_api_key)\n",
    "multimodal_model = genai.GenerativeModel(\"gemini-1.5-flash-002\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recall that text prompting and image prompting are both supported\n",
    "model_response = multimodal_model.generate_content(\"hi, how was your day?\")\n",
    "model_response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "img = Image.open(\"harrypotter.webp\")\n",
    "model_response = multimodal_model.generate_content([\"how many male and female actors are in this image? return as list of two numbers: \", img])\n",
    "model_response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using your BERT sentiment analysis code from project 3, repeat the process with the uiuc dataset\n",
    "import pandas as pd\n",
    "from transformers import pipeline # type: ignore\n",
    "\n",
    "#download bert model\n",
    "pipe = pipeline(\"text-classification\", model=\"finiteautomata/bertweet-base-sentiment-analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uiuc = pd.read_csv('uiuc.csv')\n",
    "\n",
    "def sentiment(text):\n",
    "    if not text:  \n",
    "        return None\n",
    "    try:\n",
    "        text2 = text[:128]\n",
    "        return pipe(text2)[0]['label']\n",
    "    except Exception as e:\n",
    "        return None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uiuc.loc[:, 'sentiment'] = uiuc['text'].apply(sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using the Gemini API, write a prompt to generate sentiment analysis on the same dataset\n",
    "\n",
    "#make sure to include in the prompt a limit to the type of results (positive, negative, neutral)\n",
    "\n",
    "def gemini_sentiment(text):\n",
    "    try:\n",
    "        response = multimodal_model.generate_text(\n",
    "            prompt=f\"Classify the sentiment of this text post as positive, negative, or neutral: {text}\",\n",
    "            temperature=0.0,  \n",
    "            max_output_tokens=5  \n",
    "        )\n",
    "        sentiment = response.result.strip()  \n",
    "        return sentiment\n",
    "    except Exception as e:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uiuc['gemini_sentiment'] = uiuc['text'].apply(gemini_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare the sentiment percentages, what do you notice? Does one method overestimate or underestimate the sentiment of the dataset?\n",
    "negative_percentages_bert = uiuc.groupby('label')['sentiment'].apply(lambda x: (x == 'NEGATIVE').mean() * 100)\n",
    "positive_percentages_bert = uiuc.groupby('label')['sentiment'].apply(lambda x: (x == 'POSITIVE').mean() * 100)\n",
    "neutral_percentages_bert = uiuc.groupby('label')['sentiment'].apply(lambda x: (x == 'NEUTRAL').mean() * 100)\n",
    "negative_percentages_gem = uiuc.groupby('label')['gemini_sentiment'].apply(lambda x: (x == 'NEGATIVE').mean() * 100)\n",
    "positive_percentages_gem = uiuc.groupby('label')['gemini_sentiment'].apply(lambda x: (x == 'POSITIVE').mean() * 100)\n",
    "neutral_percentages_gem = uiuc.groupby('label')['gemini_sentiment'].apply(lambda x: (x == 'NEUTRAL').mean() * 100)\n",
    "\n",
    "print(negative_percentages_bert, positive_percentages_bert, neutral_percentages_bert, negative_percentages_gem, positive_percentages_gem, neutral_percentages_gem)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find a few cases where their judgement differs, what do you think is the reason for the discrepancy? And which answer do you find more convincing?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 2: images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download 10 images from the internet with a feature you're interested in studying. e.g. gender, race, age, action, etc.\n",
    "images = [\"image1.jpg\", \"image2.jpg\", \"image3.jpg\", \"image4.jpg\", \"image5.jpg\", \"image6.jpg\", \"image7.jpg\", \"image8.jpg\", \"image9.jpg\", \"image10.jpg\"]\n",
    "#ask the model to annotate the images with the features you're interested in studying\n",
    "#choose 2 objective (clear right or wrong answer) questions and ask the model to answer them, like how many people are in the image, or what is the color of the object in the image\n",
    "#choose 2 subjective (open to interpretation) questions and ask the model to answer them, like what is the mood of the person in the image or what race/gender is the person\n",
    "for img in images:\n",
    "    image = Image.open(images)\n",
    "    annotation = multimodal_model.generate_content([\"how many people are in this image? what is the color of the peoples hair in the image? what race are the ppeople in this image? what gender are the people in this image? \", img])\n",
    "    print(f\"{img}: {annotation.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look through the responses. Is there anything you disagree with? What do you think is the reason for the discrepancy? Would you trust large scale results generated for this annotation? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 3: Network Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new graph\n",
    "G = nx.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.add_node(1)\n",
    "G.add_nodes_from([2, 3])\n",
    "#can add additional attributes to the nodes\n",
    "G.add_nodes_from([(4, {\"color\": \"red\"}), (5, {\"color\": \"green\"})])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.nodes[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(G.nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can manually add edges too\n",
    "G.add_edge(1, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.number_of_edges() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load edges from csv\n",
    "import pandas as pd\n",
    "\n",
    "edges = pd.read_csv(\"got-edges.csv\")\n",
    "\n",
    "G = nx.from_pandas_edgelist(edges, 'Source', 'Target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.number_of_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize the graph\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "nx.draw(G, with_labels=True)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the density of the graph\n",
    "\n",
    "nx.density(G)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#return highest degree nodes\n",
    "\n",
    "sorted(G.degree, key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#make dataframes with nodes and a column for each centrality measure\n",
    "df=pd.DataFrame(list(nx.degree_centrality(G).items()), columns=['node', 'degree'])\n",
    "#add column for betweeness centrality\n",
    "df['betweenness'] = list(nx.betweenness_centrality(G).values())\n",
    "#add column for closeness centrality\n",
    "df['closeness'] = list(nx.closeness_centrality(G).values())\n",
    "#add column for eigenvector centrality\n",
    "df['eigenvector'] = list(nx.eigenvector_centrality(G).values())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3a. explore this dataframe, are there huge differences between these types of centrality? What might cause this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate community structure\n",
    "import networkx.algorithms.community as nxcom\n",
    "communities = sorted(nxcom.greedy_modularity_communities(G), key=len, reverse=True)\n",
    "\n",
    "#add community to node features\n",
    "\n",
    "for i, community in enumerate(communities):\n",
    "    for node in community:\n",
    "        df.loc[df.node == node, \"community\"] = i\n",
    "\n",
    "#color nodes by community\n",
    "colors = df.community / df.community.max()\n",
    "\n",
    "nx.draw(G, with_labels=True, node_color=colors, cmap=plt.cm.tab20)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 4: make your own social network. Take either a short excerpt of a novel, tv show, movie, or real life social network you are familiar with. Make a csv modelled off of the got-edges.csv with a Source, Target, and weight column. You need to decide what constitutes an edge and node, but easiest is characters or people connected by their number of interactions. You should manually type this into the csv. Include at least 25 edges\n",
    "\n",
    "What kind of potential issues did you run into while converting it into a graph? Any ambiguities that made it difficult to decide? \n",
    "\n",
    "use either Gephi or NetworkX to calculate node centrality and community features and add a visualization of the graph here. Does it align with your understanding of the media? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instagram = pd.read_csv('instagram_mutuals.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.from_pandas_edgelist(instagram, 'Source', 'Target', ['Weight'])\n",
    "\n",
    "\n",
    "degree_centrality = nx.degree_centrality(G)\n",
    "betweenness_centrality = nx.betweenness_centrality(G)\n",
    "eigenvector_centrality = nx.eigenvector_centrality(G, weight='Weight')\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "pos = nx.spring_layout(G, seed=42)  # Layout of the graph (randomized for better spacing)\n",
    "nx.draw_networkx_nodes(G, pos, node_size=700, node_color='skyblue')\n",
    "nx.draw_networkx_edges(G, pos, width=2, alpha=0.7, edge_color='gray')\n",
    "nx.draw_networkx_labels(G, pos, font_size=10, font_color='black')\n",
    "\n",
    "plt.title('My Social Network on Instagram')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Degree Centrality:\")\n",
    "for node, centrality in degree_centrality.items():\n",
    "    print(f\"{node}: {centrality:.3f}\")\n",
    "\n",
    "print(\"\\nBetweenness Centrality:\")\n",
    "for node, centrality in betweenness_centrality.items():\n",
    "    print(f\"{node}: {centrality:.3f}\")\n",
    "\n",
    "print(\"\\nEigenvector Centrality:\")\n",
    "for node, centrality in eigenvector_centrality.items():\n",
    "    print(f\"{node}: {centrality:.3f}\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "is310-1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
